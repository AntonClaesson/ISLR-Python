{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 9 - Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) This problem involves the OJ data set which is part of the ISLR package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Purchase</th>\n",
       "      <th>WeekofPurchase</th>\n",
       "      <th>StoreID</th>\n",
       "      <th>PriceCH</th>\n",
       "      <th>PriceMM</th>\n",
       "      <th>DiscCH</th>\n",
       "      <th>DiscMM</th>\n",
       "      <th>SpecialCH</th>\n",
       "      <th>SpecialMM</th>\n",
       "      <th>LoyalCH</th>\n",
       "      <th>SalePriceMM</th>\n",
       "      <th>SalePriceCH</th>\n",
       "      <th>PriceDiff</th>\n",
       "      <th>Store7</th>\n",
       "      <th>PctDiscMM</th>\n",
       "      <th>PctDiscCH</th>\n",
       "      <th>ListPriceDiff</th>\n",
       "      <th>STORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CH</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.24</td>\n",
       "      <td>No</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CH</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.75</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>No</td>\n",
       "      <td>0.150754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CH</td>\n",
       "      <td>245</td>\n",
       "      <td>1</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.09</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>2.09</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.40</td>\n",
       "      <td>No</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091398</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MM</td>\n",
       "      <td>227</td>\n",
       "      <td>1</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>No</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CH</td>\n",
       "      <td>228</td>\n",
       "      <td>7</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.956535</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Purchase  WeekofPurchase  StoreID  PriceCH  PriceMM  DiscCH  DiscMM  \\\n",
       "0       CH             237        1     1.75     1.99    0.00     0.0   \n",
       "1       CH             239        1     1.75     1.99    0.00     0.3   \n",
       "2       CH             245        1     1.86     2.09    0.17     0.0   \n",
       "3       MM             227        1     1.69     1.69    0.00     0.0   \n",
       "4       CH             228        7     1.69     1.69    0.00     0.0   \n",
       "\n",
       "   SpecialCH  SpecialMM   LoyalCH  SalePriceMM  SalePriceCH  PriceDiff Store7  \\\n",
       "0          0          0  0.500000         1.99         1.75       0.24     No   \n",
       "1          0          1  0.600000         1.69         1.75      -0.06     No   \n",
       "2          0          0  0.680000         2.09         1.69       0.40     No   \n",
       "3          0          0  0.400000         1.69         1.69       0.00     No   \n",
       "4          0          0  0.956535         1.69         1.69       0.00    Yes   \n",
       "\n",
       "   PctDiscMM  PctDiscCH  ListPriceDiff  STORE  \n",
       "0   0.000000   0.000000           0.24      1  \n",
       "1   0.150754   0.000000           0.24      1  \n",
       "2   0.000000   0.091398           0.23      1  \n",
       "3   0.000000   0.000000           0.00      1  \n",
       "4   0.000000   0.000000           0.00      0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('../Data/OJ.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Purchase</th>\n",
       "      <th>WeekofPurchase</th>\n",
       "      <th>StoreID</th>\n",
       "      <th>PriceCH</th>\n",
       "      <th>PriceMM</th>\n",
       "      <th>DiscCH</th>\n",
       "      <th>DiscMM</th>\n",
       "      <th>SpecialCH</th>\n",
       "      <th>SpecialMM</th>\n",
       "      <th>LoyalCH</th>\n",
       "      <th>SalePriceMM</th>\n",
       "      <th>SalePriceCH</th>\n",
       "      <th>PriceDiff</th>\n",
       "      <th>Store7</th>\n",
       "      <th>PctDiscMM</th>\n",
       "      <th>PctDiscCH</th>\n",
       "      <th>ListPriceDiff</th>\n",
       "      <th>STORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.75</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0.150754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>245</td>\n",
       "      <td>1</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.09</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>2.09</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091398</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>227</td>\n",
       "      <td>1</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>228</td>\n",
       "      <td>7</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.956535</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Purchase  WeekofPurchase  StoreID  PriceCH  PriceMM  DiscCH  DiscMM  \\\n",
       "0         0             237        1     1.75     1.99    0.00     0.0   \n",
       "1         0             239        1     1.75     1.99    0.00     0.3   \n",
       "2         0             245        1     1.86     2.09    0.17     0.0   \n",
       "3         1             227        1     1.69     1.69    0.00     0.0   \n",
       "4         0             228        7     1.69     1.69    0.00     0.0   \n",
       "\n",
       "   SpecialCH  SpecialMM   LoyalCH  SalePriceMM  SalePriceCH  PriceDiff  \\\n",
       "0          0          0  0.500000         1.99         1.75       0.24   \n",
       "1          0          1  0.600000         1.69         1.75      -0.06   \n",
       "2          0          0  0.680000         2.09         1.69       0.40   \n",
       "3          0          0  0.400000         1.69         1.69       0.00   \n",
       "4          0          0  0.956535         1.69         1.69       0.00   \n",
       "\n",
       "   Store7  PctDiscMM  PctDiscCH  ListPriceDiff  STORE  \n",
       "0       0   0.000000   0.000000           0.24      1  \n",
       "1       0   0.150754   0.000000           0.24      1  \n",
       "2       0   0.000000   0.091398           0.23      1  \n",
       "3       0   0.000000   0.000000           0.00      1  \n",
       "4       1   0.000000   0.000000           0.00      0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert string data to be coded as integers\n",
    "data.Purchase=pd.Categorical(data.Purchase)\n",
    "data.Purchase=data.Purchase.cat.codes\n",
    "data.Store7=pd.Categorical(data.Store7)\n",
    "data.Store7=data.Store7.cat.codes\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Create a training set containing a random sample of 800 observations, and a test set containing the remaining observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data.Purchase\n",
    "X = data.loc[:, data.columns != 'Purchase']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=800, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Fit a support vector classifier to the training data using cost=0.01, with Purchase as the response and the other variables as predictors. Use the summary() function to produce summary statistics, and describe the results obtained.\n",
    "\n",
    "(*Purchase* is a factor with levels CH and MM indicating whether the customer purchased Citrus Hill or Minute Maid Orange Juice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CH       0.62      0.96      0.76       157\n",
      "          MM       0.77      0.20      0.32       113\n",
      "\n",
      "    accuracy                           0.64       270\n",
      "   macro avg       0.70      0.58      0.54       270\n",
      "weighted avg       0.68      0.64      0.57       270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C=0.01, kernel='linear',random_state=1).fit(X_train, y_train)\n",
    "y_predicted = svc.predict(X_test)\n",
    "y_true = y_test\n",
    "print(classification_report(y_true, y_predicted, target_names=['CH', 'MM']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reports produces classification metrics on a per-class basis, as well as averages for the total model. \n",
    "\n",
    "**Precision**: Precision is the ability of a classifier not to label an instance positive that is actually negative. It is the accuracy of positive predictions, ie. the fraction of positive predictions that are actually positive.\n",
    "\n",
    "**Recall**: Recall is the ability of a classifier to find all positive instances, i.e. the fraction of positives that were correctly identified.\n",
    "\n",
    "**F1 Score**: It is the Harmonic Mean between precision and recall, a good metric to evaluate the overall performance of the model if we don't care specifically about maximizing either precision or recall.\n",
    "\n",
    "**Support**: Number of occurences of the class.\n",
    "\n",
    "Overall, the model has bad performance which we can see from the average f1 score.\n",
    "However, we can see that it is mainly the class MM's recall that it is struggling with. The recall for MM is low, meaning that many MM observations were incorrectly classified as CH. At the same time, recall for CH is high meaning that most CH observations were correctly classified as CH."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) What are the training and test error rates\n",
    "The test error rate can also be seen in the classification report above. **Accuracy** is the same as the error rate since it is the proportion of correct classifications. In this case it is 64%. This is only a good metric to use when the dataset is more or less balanced. Let's compute the training error: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: 0.69\n"
     ]
    }
   ],
   "source": [
    "print(\"Training error: \"+str(svc.score(X_train,y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the training error is a decent amount better than the test error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Use the tune() function to select an optimal cost. Consider values in the range 0.01 to 10.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use 5-fold cross validation using gridSearchCV to choose an optimal value of C. For some reason, the gridSearch never manages to finish if I choose a value >= 9.0, which is why I try values between 0.01 and 8.9 instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 2.349473684210526, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': np.linspace(0.01, 8.9,num=20), #20 different C's between 0.01 and 8.9\n",
    "    'kernel':['linear'] #We only try linear kernel\n",
    "}\n",
    "svc_best = GridSearchCV(estimator = SVC(), param_grid = param_grid, cv = 5, n_jobs = -1)\n",
    "svc_best.fit(X_train, y_train)\n",
    "print(\"Best parameters: \")\n",
    "svc_best.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (e) Compute the training and test error rates using this new value for cost.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: 0.8375\n",
      "Test error: 0.825925925925926\n"
     ]
    }
   ],
   "source": [
    "print(\"Training error: \"+str(svc_best.score(X_train,y_train)))\n",
    "print(\"Test error: \"+str(svc_best.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time using the tuned C parameter we obtain a much better training and test error!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (f) Repeat parts (b) through (e) using a support vector machine with a radial kernel. Use the default value for gamma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CH       0.58      1.00      0.74       157\n",
      "          MM       0.00      0.00      0.00       113\n",
      "\n",
      "    accuracy                           0.58       270\n",
      "   macro avg       0.29      0.50      0.37       270\n",
      "weighted avg       0.34      0.58      0.43       270\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonclaesson/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "svc_radial = SVC(C=0.01, kernel='rbf',random_state=1).fit(X_train, y_train)\n",
    "y_predicted = svc_radial.predict(X_test)\n",
    "y_true = y_test\n",
    "print(classification_report(y_true, y_predicted, target_names=['CH', 'MM']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the radial kernel, cost 0.01 and default gamma, the classifier always predicts CH which is useless, even though that means it recieves an accuracy of 58%. Let's see if we can improve that with other gamma-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 8.9, 'gamma': 0.5556444444444445, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': np.linspace(0.01, 8.9,num=20), #20 different C's between 0.01 and 8.9\n",
    "    'gamma': np.linspace(0.0001,5,num=10),#10 different gammas \n",
    "    'kernel':['rbf'] #We only use radial kernel\n",
    "}\n",
    "svc_rad_best = GridSearchCV(estimator = SVC(), param_grid = param_grid, cv = 5, n_jobs = -1)\n",
    "svc_rad_best.fit(X_train, y_train)\n",
    "print(\"Best parameters: \")\n",
    "svc_rad_best.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: 0.8925\n",
      "Test error: 0.7444444444444445\n"
     ]
    }
   ],
   "source": [
    "print(\"Training error: \"+str(svc_rad_best.score(X_train,y_train)))\n",
    "print(\"Test error: \"+str(svc_rad_best.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting enough, we get a high training score but the test error is worse than in the linear case. This is either a matter of overfitting or underfitting, but it is not clear which one. Having a good training error with a significantly lower test score typically means that the model is overfit, having a high variance. But, as we can see the model that scored the highest uses a C of 8.9, which is the highest smoothing parameter we supplied. This indicates that the model might actually suffer from a high bias. I am not completely sure how to test what the problem is. I think it is possible to plot the test and the train error as funtions of the training set size, and evaluate that graph. However I will not do that now. Instead I will evaluate the polynomial kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (g) Repeat parts (b) through (e) using a support vector machine with a polynomial kernel. Set degree=2.\n",
    "\n",
    "In Scikit-learn the polynomial kernel is defined as $(\\gamma \\langle x, x'\\rangle + r)^d$ where $r$ is specified by the keyword coef0. To use the same kernel as specified in the book we therefore set $\\gamma = r = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CH       0.83      0.88      0.85       157\n",
      "          MM       0.82      0.74      0.78       113\n",
      "\n",
      "    accuracy                           0.82       270\n",
      "   macro avg       0.82      0.81      0.81       270\n",
      "weighted avg       0.82      0.82      0.82       270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_pol = SVC(C=0.01, kernel='poly',coef0=1.0,gamma=1.0,degree=2,random_state=1).fit(X_train, y_train)\n",
    "y_predicted = svc_pol.predict(X_test)\n",
    "y_true = y_test\n",
    "print(classification_report(y_true, y_predicted, target_names=['CH', 'MM']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2nd degree polynomial kernel when simply using C=0.01 performs as good as the best other one we found! Let's try tuning it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.01, 'kernel': 'poly'}\n",
      "\n",
      "Training error: 0.62\n",
      "Test error: 0.5814814814814815\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': np.linspace(0.01, 8.9,num=20), #20 different C's between 0.01 and 10.0\n",
    "    'kernel':['poly'], #We only try polynomial kernel\n",
    "}\n",
    "svc_pol_best = GridSearchCV(estimator = SVC(coef0=1.0, degree=2), param_grid = param_grid, cv = 5, n_jobs = -1)\n",
    "svc_pol_best.fit(X_train, y_train)\n",
    "print(\"Best parameters: \"+str(svc_pol_best.best_params_))\n",
    "print()\n",
    "\n",
    "print(\"Training error: \"+str(svc_pol_best.score(X_train,y_train)))\n",
    "print(\"Test error: \"+str(svc_pol_best.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (h) Overall, which approach seems to give the best results on this data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear or polynomial kernels clearly performed the best on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
